{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Galaxea Documentation","text":"<p>Welcome. Explore simulation, datasets, and diffusion policies for the Galaxea R1 series.</p>"},{"location":"#quick-links","title":"Quick links","text":"<ul> <li>Galaxea DP: end-to-end diffusion policy pipeline</li> <li>Galaxea Manipulation Simulator: environments, demo collection, conversion, baselines</li> </ul>"},{"location":"#get-started","title":"Get started","text":"<ol> <li>Install Galaxea DP and dependencies</li> <li>Collect or download data</li> <li>Train and evaluate</li> </ol> <p>Tip: Use the top navigation tabs or search to jump directly to sections.</p>"},{"location":"galaxea_dp/","title":"\ud83e\udd16 Galaxea DP","text":"<p>GalaxeaDP is the open implementation of the diffusion policy algorithm, compatible with <code>GalaxeaManipSim</code> and <code>GalaxeaLeRobot</code>. It enables end-to-end pipelines for the Galaxea R1 series.</p>"},{"location":"galaxea_dp/#features","title":"\u2728 Features","text":"<ul> <li>Full simulation pipeline from data to evaluation</li> <li>One-click scripts</li> <li>LeRobot dataset format</li> <li>Open-loop evaluation</li> <li>EE and joint control modes</li> </ul>"},{"location":"galaxea_dp/#installation","title":"\ud83d\ude80 Installation","text":"<pre><code>conda create -n opengalaxea python=3.10\nconda activate opengalaxea\n\ngit clone https://github.com/OpenGalaxea/GalaxeaDP.git\ncd GalaxeaDP\npip install -r requirements.txt\n\ncd ..\ngit clone https://github.com/OpenGalaxea/GalaxeaManipSim.git\ncd GalaxeaManipSim\npip install --no-deps -e .\n\ncd ..\ngit clone https://github.com/OpenGalaxea/GalaxeaLeRobot.git\ncd GalaxeaLeRobot\npip install --no-deps -e .\n</code></pre>"},{"location":"galaxea_dp/#quick-start","title":"\u26a1 Quick Start","text":"<pre><code>bash scripts/sim_r1pro_blocks.sh\n</code></pre>"},{"location":"galaxea_dp/#data-generation-conversion","title":"\ud83d\udee0 Data Generation &amp; Conversion","text":"<ul> <li>Collect demos in <code>GalaxeaManipSim</code></li> <li>Replay with IK to filter and collect images</li> <li>Convert to LeRobot format</li> </ul> <pre><code>python -m galaxea_sim.scripts.collect_demos --env-name $env --num-demos 100 --datasets_dir data\npython -m galaxea_sim.scripts.replay_demos --env-name $env --target_controller_type bimanual_relaxed_ik --num-demos 100 --dataset_dir data\npython -m galaxea_sim.scripts.convert_single_galaxea_sim_to_galaxea_lerobot --task $env --tag replayed --robot r1_pro --use_eef --dataset_dir $dataset_dir\n</code></pre>"},{"location":"galaxea_dp/#optional-download-datamodels","title":"Optional: Download Data/Models","text":"<pre><code># Data\ngdown --folder https://drive.google.com/drive/folders/1qBY5OuTXrP3r1H8X9duUekyTEfgDFwvb\n# Models\ngdown --folder https://drive.google.com/drive/folders/1zWgMPXyWryNDz7pHTJzlwPjoszMGd3q1\n</code></pre>"},{"location":"galaxea_dp/#policy-sample","title":"\ud83e\udde0 Policy Sample","text":"<pre><code>sample = dict(\n    obs=dict(\n        left_ee_pose=torch.Tensor(obs_size, 7),\n        right_ee_pose=torch.Tensor(obs_size, 7),\n        left_arm=torch.Tensor(obs_size, arm_size),\n        right_arm=torch.Tensor(obs_size, arm_size),\n        left_gripper=torch.Tensor(obs_size, 1),\n        right_gripper=torch.Tensor(obs_size, 1),\n        episode_start_left_ee_pose=torch.Tensor(1, 7),\n        episode_start_right_ee_pose=torch.Tensor(1, 7),\n        head_rgb=torch.Tensor(obs_size, 3, H, W),\n        left_wrist_rgb=torch.Tensor(obs_size, 3, H, W),\n        right_wrist_rgb=torch.Tensor(obs_size, 3, H, W),\n    ),\n    action=dict(\n        left_ee_pose=torch.Tensor(chunk_size, 7),\n        right_ee_pose=torch.Tensor(chunk_size, 7),\n        left_arm=torch.Tensor(chunk_size, arm_size),\n        right_arm=torch.Tensor(chunk_size, arm_size),\n        left_gripper=torch.Tensor(chunk_size, 1),\n        right_gripper=torch.Tensor(chunk_size, 1),\n    ),\n    gt_action=action,\n)\n</code></pre>"},{"location":"galaxea_dp/#training","title":"\ud83d\udee0 Training","text":"<pre><code>export GALAXEA_DP_WORK_DIR=out\nbash train.sh trainer.devices=[0,1,2,3] task=sim/R1ProBlocksStackEasy_eef\n</code></pre>"},{"location":"galaxea_dp/#evaluation","title":"\ud83d\udcca Evaluation","text":"<pre><code>bash eval_lerobot.sh trainer.devices=[0] task=open_galaxea/&lt;robot&gt;/&lt;task&gt; \\\n  ckpt_path=out/open_galaxea/&lt;robot&gt;/&lt;task&gt;/&lt;time&gt;/checkpoints/step_20000.ckpt\n\nbash eval_sim.sh trainer.devices=[0] task=sim/&lt;task&gt; \\\n  ckpt_path=out/sim/&lt;task&gt;/checkpoints/step_20000.ckpt\n</code></pre>"},{"location":"galaxea_dp/#dataset-r1pro-example","title":"\ud83d\udcc2 Dataset (R1Pro example)","text":"<pre><code>\"observation.images.head_rgb\": (360, 640, 3)\n\"observation.images.left_wrist_rgb\": (480, 640, 3)\n\"observation.images.right_wrist_rgb\": (480, 640, 3)\n\"observation.state.left_arm\": (7,)\n\"observation.state.left_arm.velocities\": (7,)\n\"observation.state.right_arm\": (7,)\n\"observation.state.right_arm.velocities\": (7,)\n\"observation.state.left_ee_pose\": (7,)\n\"observation.state.right_ee_pose\": (7,)\n\"observation.state.left_gripper\": (1,)\n\"observation.state.right_gripper\": (1,)\n\"observation.state.chassis\": (3,)\n\"observation.state.chassis.velocities\": (6,)\n\"observation.state.torso\": (4,)\n\"observation.state.torso.velocities\": (4,)\n\"action.left_ee_pose\": (7,)\n\"action.right_ee_pose\": (7,)\n\"action.left_arm\": (7,)\n\"action.right_arm\": (7,)\n\"action.left_gripper\": (1,)\n\"action.right_gripper\": (1,)\n</code></pre>"},{"location":"galaxea_dp/#license-acknowledgements","title":"License &amp; Acknowledgements","text":"<ul> <li>MIT License</li> <li>Built on Diffusion Policy, LeRobot, Robotwin</li> </ul>"},{"location":"galaxea_dp/#citation","title":"Citation","text":"<pre><code>@inproceedings{GalaxeaDP,\n  title={Galaxea Diffusion Policy},\n  author={Galaxea Team},\n  year={2025}\n}\n</code></pre>"},{"location":"galaxea_manipsim/","title":"\ud83e\udd16 Galaxea Manipulation Simulator","text":"<p>Provides simulation benchmarks, expert demo pipelines, and baseline policies for the Galaxea R1 series. Use it to collect demos, convert to <code>LeRobot</code> datasets, and train/evaluate Diffusion Policies.</p>"},{"location":"galaxea_manipsim/#features","title":"\u2728 Features","text":"<ul> <li>30+ environments across 17 tasks</li> <li>One-command setup and asset registration</li> <li>Joint-space and relaxed-ik (EEF) controllers</li> <li>LeRobot-compatible datasets</li> <li>Baseline DP training and evaluation with videos/metrics</li> </ul>"},{"location":"galaxea_manipsim/#installation-standalone","title":"\ud83d\ude80 Installation (Standalone)","text":"<p>Prereq: Linux + CUDA GPU</p> <pre><code>conda create -n galaxea-sim python=3.10 -y\nconda activate galaxea-sim\npip install -e .\n\n# Install LeRobot\ncd ..\ngit clone https://github.com/huggingface/lerobot.git\ncd lerobot\ngit checkout a5e0aae13a3efd0080ac7ab6b461980d644014ab\npip install -e .\nexport PYTHONPATH=\"your_lerobot_codebase_path:$PYTHONPATH\"\n</code></pre> <p>If installing together with Galaxea-DP, see the Galaxea DP installation.</p> <p>Download assets:</p> <pre><code>gdown https://drive.google.com/file/d/1ZvtCv1H4FLrse_ElUWzsVDt8xRK4CyaC/\nunzip robotwin_models.zip\nmv robotwin_models galaxea_sim/assets/\n</code></pre> <p>Heads-up: If you hit <code>datasets</code> cache conflicts, clear <code>~/.cache/huggingface/datasets</code>.</p>"},{"location":"galaxea_manipsim/#collect-demos","title":"\ud83c\udfae Collect Demos","text":"<p>Supported robots, example tasks, and controllers: - R1: <code>R1DualBottlesPickEasy</code> \u2014 joint_position / relaxed_ik - R1 Pro: <code>R1ProBlocksStackEasy</code> \u2014 joint_position / relaxed_ik - R1 Lite: <code>R1LiteBlocksStackEasy</code> \u2014 joint_position</p>"},{"location":"galaxea_manipsim/#1-generate-raw-demos-mplib","title":"1) Generate raw demos (mplib)","text":"<pre><code>python -m galaxea_sim.scripts.collect_demos --env-name R1DualBottlesPickEasy --num-demos 100\npython -m galaxea_sim.scripts.collect_demos --env-name R1ProBlocksStackEasy --num-demos 100\npython -m galaxea_sim.scripts.collect_demos --env-name R1LiteBlocksStackEasy --num-demos 100\n</code></pre> <p>Default <code>--obs_mode</code> is <code>state</code>. Data saved under <code>datasets/&lt;env-name&gt;/&lt;date-time&gt;</code>.</p>"},{"location":"galaxea_manipsim/#2-replay-demos-with-controllers","title":"2) Replay demos with controllers","text":"<pre><code>python -m galaxea_sim.scripts.replay_demos --env-name R1DualBottlesPickEasy --target_controller_type bimanual_joint_position --num-demos 100\npython -m galaxea_sim.scripts.replay_demos --env-name R1ProBlocksStackEasy --target_controller_type bimanual_relaxed_ik --num-demos 100\npython -m galaxea_sim.scripts.replay_demos --env-name R1LiteBlocksStackEasy --target_controller_type bimanual_joint_position --num-demos 100\n</code></pre> <p>Replay filters infeasible IK solutions, stores images/depths under <code>datasets/&lt;env-name&gt;/final</code>.</p>"},{"location":"galaxea_manipsim/#train-policies","title":"\ud83d\udee0 Train Policies","text":""},{"location":"galaxea_manipsim/#convert-to-lerobot-dataset","title":"Convert to LeRobot dataset","text":"<p>For Galaxea DP use <code>convert_single_galaxea_sim_to_galaxea_lerobot</code> (add <code>--use_eef</code> for relaxed_ik). For LeRobot DP use <code>convert_single_galaxea_sim_to_lerobot</code>.</p> <pre><code># LeRobot DP examples\npython -m galaxea_sim.scripts.convert_single_galaxea_sim_to_lerobot --task R1DualBottlesPickEasy --tag final --robot r1\npython -m galaxea_sim.scripts.convert_single_galaxea_sim_to_lerobot --task R1ProBlocksStackEasy --tag final --robot r1_pro\npython -m galaxea_sim.scripts.convert_single_galaxea_sim_to_lerobot --task R1LiteBlocksStackEasy --tag final --robot r1_lite\n\n# EEF examples\npython -m galaxea_sim.scripts.convert_single_galaxea_sim_to_lerobot --robot r1_pro --task R1ProDualBottlesPickEasy --tag final --use_eef\npython -m galaxea_sim.scripts.convert_single_galaxea_sim_to_lerobot --robot r1_pro --task R1ProBlocksStackEasy --tag final --use_eef\n</code></pre> <p>Optional <code>--use_video</code> stores images as video. Ensure ffmpeg is installed; change vcodec to <code>libx264</code> if needed in <code>.../site-packages/lerobot/common/datasets/video_utils.py</code>.</p>"},{"location":"galaxea_manipsim/#data-structure-after-converting","title":"Data structure after converting","text":""},{"location":"galaxea_manipsim/#galaxea-dp","title":"Galaxea DP","text":"<pre><code># Images\nobservation.images.head_rgb: (224, 224, 3)\nobservation.images.left_wrist_rgb: (224, 224, 3)\nobservation.images.right_wrist_rgb: (224, 224, 3)\n# Depth\nobservation.depth.head_depth: (224, 224)\n# States/actions (EEF controller example; arm_dof=6 for R1/R1Lite, 7 for R1Pro)\nobservation.state.left_arm_joints: (arm_dof,)\nobservation.state.left_gripper: (1,)\nobservation.state.right_arm_joints: (arm_dof,)\nobservation.state.right_gripper: (1,)\naction.left_arm_joints: (arm_dof,)\naction.left_gripper: (1,)\naction.right_arm_joints: (arm_dof,)\naction.right_gripper: (1,)\n</code></pre>"},{"location":"galaxea_manipsim/#lerobot-dp","title":"LeRobot DP","text":"<pre><code># Images\nobservation.images.rgb_head: (224, 224, 3)\nobservation.images.rgb_left_hand: (224, 224, 3)\nobservation.images.rgb_right_hand: (224, 224, 3)\n# States/actions (EEF controller)\nobservation.state: (2*arm_dof + 2,)\naction: (2*arm_dof + 2,)\n# States/actions (joints controller)\nobservation.state: (16,)\naction: (16,)\n</code></pre>"},{"location":"galaxea_manipsim/#train-and-evaluate","title":"Train and Evaluate","text":"<pre><code>python -m galaxea_sim.scripts.train_lerobot_dp_policy --task R1DualBottlesPickEasy\npython -m galaxea_sim.scripts.train_lerobot_dp_policy --task R1ProBlocksStackEasy\npython -m galaxea_sim.scripts.train_lerobot_dp_policy --task R1LiteBlocksStackEasy\n\npython -m galaxea_sim.scripts.eval_lerobot_dp_policy --task R1DualBottlesPickEasy --pretrained-policy-path outputs/train/R1DualBottlesPickEasy/diffusion/.../checkpoint --target_controller_type bimanual_joint_position\npython -m galaxea_sim.scripts.eval_lerobot_dp_policy --task R1ProBlocksStackEasy --pretrained-policy-path outputs/train/R1ProBlocksStackEasy/diffusion/.../checkpoint --target_controller_type bimanual_joint_position\npython -m galaxea_sim.scripts.eval_lerobot_dp_policy --task R1LiteBlocksStackEasy --pretrained-policy-path outputs/train/R1LiteBlocksStackEasy/diffusion/.../checkpoint --target_controller_type bimanual_joint_position\n</code></pre>"},{"location":"galaxea_manipsim/#success-rate-100-rollouts-joints-controller","title":"\ud83d\udcc8 Success Rate (100 rollouts; joints controller)","text":"<ul> <li>R1 Dual Bottles Pick Easy: OpenDP 98%, LeRobot 98%</li> <li>R1 Pro Blocks Stack Easy: OpenDP 68%, LeRobot 64%</li> <li>R1 Lite Blocks Stack Easy: OpenDP 51%, LeRobot 42%</li> </ul>"},{"location":"galaxea_manipsim/#license-acknowledgements","title":"License &amp; Acknowledgements","text":"<ul> <li>MIT License</li> <li>Built on Diffusion Policy, LeRobot, Robotwin</li> </ul>"},{"location":"galaxea_manipsim/#citation","title":"Citation","text":"<pre><code>@inproceedings{GalaxeaManipSim,\n  title={Galaxea Manipulation Simulator},\n  author={Galaxea Team},\n  year={2025}\n}\n</code></pre>"}]}